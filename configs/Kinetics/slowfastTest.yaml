TRAIN:
  ENABLE: False
  DATASET: kinetics
  BATCH_SIZE: 4
  EVAL_PERIOD: 50
  CHECKPOINT_PERIOD: 5
  AUTO_RESUME: True
DATA:
  # PATH_TO_DATA_DIR: ../TestData/
  PATH_TO_DATA_DIR: ../DataSet/
  NUM_FRAMES: 32
  SAMPLING_RATE: 2
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 256
  INPUT_CHANNEL_NUM: [3, 3]
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 7
RESNET:
  ZERO_INIT_FINAL_BN: True
  WIDTH_PER_GROUP: 64
  NUM_GROUPS: 1
  DEPTH: 50
  TRANS_FUNC: bottleneck_transform
  STRIDE_1X1: False
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [2, 2]]
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [1, 1]]
NONLOCAL:
  LOCATION: [[[], []], [[], []], [[], []], [[], []]]
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
BN:
  USE_PRECISE_STATS: True
  NUM_BATCHES_PRECISE: 200
SOLVER:
  BASE_LR: 0.8
  LR_POLICY: cosine
  MAX_EPOCH: 100
  MOMENTUM: 0.9
  WEIGHT_DECAY: 1e-4
  WARMUP_EPOCHS: 34.0
  WARMUP_START_LR: 0.01
  OPTIMIZING_METHOD: sgd
MODEL:
  NUM_CLASSES: 10
  ARCH: slowfast
  MODEL_NAME: SlowFast
  LOSS_FUNC: cross_entropy
  DROPOUT_RATE: 0.5
TEST:
  ENABLE: True
  DATASET: kinetics
  BATCH_SIZE: 10
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  # CHECKPOINT_FILE_PATH: ./result2/slowfast/checkpoints/checkpoint_epoch_00090.pyth

DATA_LOADER:
  NUM_WORKERS: 2
  PIN_MEMORY: False
NUM_GPUS: 2
NUM_SHARDS: 1
RNG_SEED: 3407

TENSORBOARD:
  ENABLE: True
  CLASS_NAMES_PATH: tensorboard/class_name_new.json
  CATEGORIES_PATH: tensorboard/parent_child_new.json
  MODEL_VIS:
    ENABLE: False
    MODEL_WEIGHTS: False # Set to True to visualize model weights.
    ACTIVATIONS: False # Set to True to visualize feature maps.
    INPUT_VIDEO: True
    # Set to True to visualize the input video(s) for the corresponding feature maps.
    LAYER_LIST: ['headclassification/pathway0_avgpool', 'headclassification/pathway1_avgpool'] # List of layer names to visualize weights and activations for.['s5/pathway1_res2', 's5/pathway0_res2'] \['model/blocks/11','model/blocks/11']
    GRAD_CAM:
      ENABLE: True
      LAYER_LIST: ['headclassification/pathway0_avgpool', 'headclassification/pathway1_avgpool']
      # List of CNN layers to use for Grad-CAM visualization method.
                  # The number of layer must be equal to the number of pathway(s).
      # ['s1/pathway0_stem', 's1/pathway1_stem']  ['s2/pathway0_res2', 's2/pathway1_res2']   
      # ['s3/pathway0_res3', 's3/pathway1_res3']  ['s4/pathway0_res5', 's4/pathway1_res5']
      # ['s5/pathway0_res2', 's5/pathway1_res2']  ['headclassification/pathway0_avgpool', 'headclassification/pathway1_avgpool']
  WRONG_PRED_VIS:
    ENABLE: True
    SUBSET_PATH: tensorboard/subset.txt
    TAG: Incorrectly classified videos.
  CONFUSION_MATRIX:
    ENABLE: True
    FIGSIZE: [8, 8]
    SUBSET_PATH: tensorboard/subset.txt
  HISTOGRAM:
    ENABLE: True
    FIGSIZE: [8, 8]
    SUBSET_PATH: tensorboard/subset.txt
    TOPK: 5

DEMO:
  ENABLE: False
  LABEL_FILE_PATH: tensorboard/class_name_last.json
  INPUT_VIDEO:  img/phone_JL_06.mp4  # /home/pe432442/Desktop/some_video.mp4
  OUTPUT_FILE:  img/out.mp4 # /home/pe432442/Desktop/sf-out
  # THREAD_ENABLE: True
  NUM_VIS_INSTANCES: 1
  NUM_CLIPS_SKIP: 4

OUTPUT_DIR: result2/slowfastTest/


# DEMO:
#   ENABLE: True
#   LABEL_FILE_PATH:     # Path to json file providing class_name - id mapping.
#   INPUT_VIDEO: ../TestData/talk_DCX_01.mp4 # Path to input video file.
#   OUTPUT_FILE: # Path to output video file to write results to.
#                # Leave an empty string if you would like to display results to a window.
#   THREAD_ENABLE: # Run video reader/writer in the background with multi-threading.
#   NUM_VIS_INSTANCES: # Number of CPU(s)/processes use to run video visualizer.
#   NUM_CLIPS_SKIP: # Number of clips to skip prediction/visualization
#                   # (mostly to smoothen/improve display quality with wecam input).
# DEMO:
#   ENABLE: True
#   OUTPUT_FILE: yourPath/output.mp4
#   LABEL_FILE_PATH:  yourPath/ava_classnames.json
#   INPUT_VIDEO: img/ # Path to a video file or image folder
#   PREDS_BOXES: yourPath/ava_detection_train_boxes_and_labels_include_negative.csv # Path to pre-computed bouding boxes in AVA format.
#   GT_BOXES: yourPath/ava_train_v2.2.csv # Path to ground-truth boxes and labels in AVA format (optional).


# TENSORBOARD:
#   ENABLE: True
#   LOG_DIR: tensorboard/log
#   # Leave empty to use cfg.OUTPUT_DIR/runs-{cfg.TRAIN.DATASET} as path.
#   CLASS_NAMES_PATH: tensorboard/class_name_last.json
#   # Path to json file providing class_name - id mapping.
#   CATEGORIES_PATH: tensorboard/parent_child_last.json
#   CONFUSION_MATRIX:
#     ENABLE: True
#     SUBSET_PATH: tensorboard/subset_last.txt
#     # Path to txt file contains class names separated by newline characters.
#                  # Only classes in this file will be visualized in the confusion matrix.
#   HISTOGRAM:
#     ENABLE: True
#     TOPK: 5   
#     # Top-k most frequently predicted classes for each class in the dataset.
#     SUBSET_PATH: tensorboard/subset_last.txt
#     # Path to txt file contains class names separated by newline characters.
#                  # Only classes in this file will be visualized with histograms.



# nohup python tools/run_net.py --cfg configs/Kinetics/test.yaml > result/slowfast2/vis.log 2>&1 